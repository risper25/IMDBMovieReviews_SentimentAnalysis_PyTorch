{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BTobaPqr2MOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2febe52-82d8-46e8-a182-7064036b008d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lteDpccdFlyp",
        "outputId": "203bc8fa-addf-4d20-e5b2-42fb9e39805f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "codi8ttl1YTX",
        "outputId": "6b501eee-366c-472a-c306-50b8ce8c9bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "Skipping line 5506: unexpected end of data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               review sentiment\n",
              "0   One of the other reviewers has mentioned that ...  positive\n",
              "1   A wonderful little production. <br /><br />The...  positive\n",
              "2   I thought this was a wonderful way to spend ti...  positive\n",
              "3   Basically there's a family where a little boy ...  negative\n",
              "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "..                                                ...       ...\n",
              "95  Daniel Day-Lewis is the most versatile actor a...  positive\n",
              "96  My guess would be this was originally going to...  negative\n",
              "97  Well, I like to watch bad horror B-Movies, cau...  negative\n",
              "98  This IS the worst movie I have ever seen, as w...  negative\n",
              "99  I have been a Mario fan for as long as I can r...  positive\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87822769-0562-4f2a-984e-2a11690be1ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Daniel Day-Lewis is the most versatile actor a...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>My guess would be this was originally going to...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Well, I like to watch bad horror B-Movies, cau...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>This IS the worst movie I have ever seen, as w...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>I have been a Mario fan for as long as I can r...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87822769-0562-4f2a-984e-2a11690be1ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87822769-0562-4f2a-984e-2a11690be1ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87822769-0562-4f2a-984e-2a11690be1ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train=pd.read_csv(\"/content/IMDBDataset.csv\",error_bad_lines=False,engine=\"python\")\n",
        "train.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "kU6L9nFXkPO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "0-O2ozCC2SdF",
        "outputId": "565decd6-bf89-4977-a53c-916ce93bd533"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd3c4bd5850>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#distribution of sentiments\n",
        "train[\"sentiment\"].value_counts().plot(kind='bar')\n",
        "\n",
        "#distribution of text length "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['len_r']=train['review'].apply(lambda x: len(x.split()))\n",
        "train['len_r'].agg(['mean','max','min'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DOSI9hsFmha",
        "outputId": "14b90b2f-8d9c-434a-94ff-ac7f774d7502"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean     232.704215\n",
              "max     1737.000000\n",
              "min       14.000000\n",
              "Name: len_r, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kVNkezTDAAg",
        "outputId": "3801f974-ffc7-466d-f20c-12132989260f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "len_r        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#check for null values and duplicates\n",
        "train.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEXT PREPEROCESSING"
      ],
      "metadata": {
        "id": "eBc5uoV5gGyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eWDiv3OhDEw9"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    #remove links\n",
        "    text = re.sub('http://\\S+|https://\\S+',' ', text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    #remove html tags\n",
        "    clean = re.compile('<[^>]*>')\n",
        "    text = re.sub(clean,' ', text)\n",
        "    #remove numbers\n",
        "    #remove punctuations\n",
        "    #remove non letters\n",
        "    text = re.sub('[^a-zA-z\\s]',' ',text)\n",
        "    #convert to lower case and split\n",
        "    text = text.lower()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in text.split() if word not in (stop_words)]\n",
        "\n",
        "def lemm(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word) for word in text] \n",
        "\n",
        "def stemer(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(word) for word in text]\n",
        "    \n",
        "def correct(text):\n",
        "   textblob = [TextBlob(word).correct().string for word in text]\n",
        "   return textblob   "
      ],
      "metadata": {
        "id": "dE-_cOP3osvG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correct(\"interestin moviie\")"
      ],
      "metadata": {
        "id": "CTNFG_oSh1qv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text=clean(text)\n",
        "    #remove stop words\n",
        "    text=remove_stopwords(text)\n",
        "    #text=correct(text)\n",
        "    text=lemm(text)\n",
        "    #text= stemer(text)\n",
        "    return ' '.join(text)\n",
        "   \n",
        "   \n"
      ],
      "metadata": {
        "id": "i_ObNdV0k54f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['review']=train['review'].apply(lambda x: preprocess_text(x))\n",
        "train.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CY9EE8fcm0aV",
        "outputId": "7097e0de-d599-4517-b8e5-7df70591841e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  len_r\n",
              "0  one reviewer mentioned watching oz episode hoo...  positive    307\n",
              "1  wonderful little production filming technique ...  positive    162\n",
              "2  thought wonderful way spend time hot summer we...  positive    166\n",
              "3  basically family little boy jake think zombie ...  negative    138\n",
              "4  petter mattei love time money visually stunnin...  positive    230"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c1562ef-b0ec-4c03-b39b-790a50a46467\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>len_r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewer mentioned watching oz episode hoo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production filming technique ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>positive</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically family little boy jake think zombie ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c1562ef-b0ec-4c03-b39b-790a50a46467')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c1562ef-b0ec-4c03-b39b-790a50a46467 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c1562ef-b0ec-4c03-b39b-790a50a46467');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xv3Bcu3s-s1E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsf1fAr1-rw4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reviews=train['review'].values\n",
        "reviews[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "DmlAKILP4er3",
        "outputId": "edae302f-c2c6-4834-c7f4-6ee02f71498d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sure would like see resurrection dated seahunt series tech today would bring back kid excitement grew black white tv seahunt gunsmoke hero every week vote comeback new sea hunt need change pace tv would work world water adventure oh way thank outlet like view many viewpoint tv many movie ole way believe got wanna say would nice read plus point sea hunt rhyme would line would let submit leave doubt quit must go let'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset"
      ],
      "metadata": {
        "id": "vlZViMb1pLBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "def build_vocab(data):\n",
        "    reviews=data['review'].values\n",
        "    text=' '.join(reviews)\n",
        "    text=word_tokenize(text)\n",
        "    #build vocab\n",
        "    counter = Counter(text)\n",
        "    vocab = sorted(counter, key=counter.get, reverse=True)\n",
        "    #vocab to int\n",
        "    vocab_int=dict()\n",
        "    vocab_int['<padding>']=0\n",
        "    vocab_int={word:i+1 for i,word in enumerate(vocab)}\n",
        "    return vocab_int"
      ],
      "metadata": {
        "id": "NN2XUJEip4RY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "vocab= build_vocab(train)\n",
        "with open(\"sample.json\", \"w\") as outfile:\n",
        "    json.dump(vocab, outfile)"
      ],
      "metadata": {
        "id": "1f1_nW5YkaO1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_review(text,vocab=vocab):\n",
        "  \n",
        "    encoded_review=[vocab[word] for word in word_tokenize(text) if word in vocab]\n",
        "       \n",
        "    return encoded_review\n",
        "\n",
        "def encode_labels(data):\n",
        "    labels = data['sentiment'].values\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "    encoded_labels = encoder.fit_transform(labels)\n",
        "    return encoded_labels \n",
        "\n"
      ],
      "metadata": {
        "id": "HxsxeQ8KoKk2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7p1H586tDRGn"
      },
      "outputs": [],
      "source": [
        "#padding and truncate reviews\n",
        "#on the left\n",
        "def padding(reviews,seq_len):\n",
        "    features=np.zeros((len(reviews),seq_len),dtype=int)\n",
        "    for i,row in enumerate(reviews):\n",
        "        features[i,-len(row):]=np.array(row)[:seq_len]\n",
        "    return features      \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_val(reviews,leng):\n",
        "    for i in range(5):\n",
        "        print(reviews[i][:leng])"
      ],
      "metadata": {
        "id": "ToGcUEyfpKH0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare(data):\n",
        "    train['review']=train['review'].apply(lambda x: encode_review(x))\n",
        "    rev=train['review'].values.tolist()\n",
        "   \n",
        "    labels=encode_labels(data)\n",
        "    rev=padding(rev,128)\n",
        "    print_val(rev,100)\n",
        "    return rev,labels,len(vocab)"
      ],
      "metadata": {
        "id": "LL9RNqNdzyyw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rev,labels,vocab_size=prepare(train)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxw255R-7aKC",
        "outputId": "9c51e3f4-f689-4923-b79b-798d56a039ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    3   979   802    62  2166   180  2362   103   532   522    19    27\n",
            "  2915  2166  6725 16610    16   453   111   103   214    28  1640    25\n",
            "  8440  1814 11742    25   747  1960  1559   470   301   453  3131   220\n",
            "   239   214   325  2166 10294   243  7737  4309  2528   651 21689   837\n",
            "  1072 10295   385  5369  2273  1106  1870  2017   826   224 16611 13652\n",
            "   184  4893  2479   385   215    40 10296  3630 11743  4894  1373   877\n",
            "  1989 13653   227  3313  5370  1560 10297  7738    34   134   141     5\n",
            "    44   183  1147    25   527    93    28    25     5  2480   684    84\n",
            "   242  4154  2578   137]\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0   267    36   211  1207  1502 16612    67\n",
            "     6  1731  1198    65 10298   435 13654   201  1898   333   196    35\n",
            "   398    15  2091   369  3516    89 21690   386  2314   280    13 10299\n",
            "   625 11745  1107  1585  7203  2248    15   192    62 16613   303  1842\n",
            "   196  4508   211     3    23   889    95    29  1898    14    47   215\n",
            "    36    27   778  1676]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0   91  267   24 1223    6  704 1199 2051 1073  798 7740  550   62\n",
            "  462 1814   95   33 4509  288 1701    8 1391   11   15 5134 5371  963\n",
            "  277  107  506  710  769   82 1990 4155   91 2529 2092 1657   53 1134\n",
            "  926  291   40   71 2209   39    5 1188    3 2092   95   42 2480   44\n",
            " 1338   34]\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0   540   105    36   206  4896    30   507  4001\n",
            "   528  1074     6     1  5638  1603  1245  1000  4896   927   335  3631\n",
            "   266   507   488    19    68    12     2    99   936   471   304   304\n",
            "     1  1786   528 13657]\n",
            "[    0     0     0 21694  5135    39     6   185  1815  1353     2    31\n",
            "   268  5135   634    71  4311  2424   235  2132     1   104   861    71\n",
            "   185   394   775    20   190   409  1392  4312  2425 21695    69   388\n",
            "    58  4313   108   667     6    72   784   190     8   338  3880     3\n",
            "  3518     3    24    79   258   259     3   104    32   883    82  1871\n",
            "  8442     2  3314 11746    37   565    13    20   358    87   358 11747\n",
            "    27     3     9   865   242   190   659  4314     3  9238   101   385\n",
            "   532    43   153   235  2132    63  3416  9239     3 21696   292    20\n",
            "  1392    45     7   268]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35954"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "def load_data(reviews,labels,batch_size):\n",
        "    #train_target = torch.tensor(labels.astype(np.float32))\n",
        "    #train = torch.tensor(reviews.astype(np.float32)) \n",
        "    train_tensor = data_utils.TensorDataset(torch.from_numpy(reviews), torch.from_numpy(labels)) \n",
        "    train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True, drop_last=True)\n",
        "    return train_loader"
      ],
      "metadata": {
        "id": "AHMRFkhRkQgB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(reviews,labels):\n",
        "    X_train, X_rem, y_train, y_rem = train_test_split(rev,labels, train_size=0.8)\n",
        "    test_size = 0.5\n",
        "    X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=test_size)\n",
        "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n"
      ],
      "metadata": {
        "id": "R9X1JNzqSSPb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, X_test, y_train, y_valid, y_test=split_data(reviews,labels)"
      ],
      "metadata": {
        "id": "wevIxRB2wDJo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=128\n",
        "train_loader=load_data(X_train,y_train,batch_size)\n",
        "valid_loader=load_data( X_valid,y_valid,batch_size)\n",
        "test_loader=load_data(X_test,y_test,32)"
      ],
      "metadata": {
        "id": "m1IdQkHfXRq7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter=iter(train_loader)\n",
        "x,y=dataiter.next()\n",
        "print(x.size())\n",
        "print(x)\n",
        "print(\"=\"*80)\n",
        "print(y.size())\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD_qlGPGYto0",
        "outputId": "10a7eba6-986f-4d1d-cd28-b5fb94be6972"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 128])\n",
            "tensor([[   0,    0,    0,  ..., 6989,  699, 3135],\n",
            "        [   0,    0,    0,  ...,  344, 2067, 2067],\n",
            "        [   0,    0,    0,  ..., 7965, 2314,  251],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,   52,  115, 5766],\n",
            "        [   0,    0,    0,  ..., 1031, 2167,    3],\n",
            "        [   0,    0,    0,  ...,   62,  318,   18]])\n",
            "================================================================================\n",
            "torch.Size([128])\n",
            "tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
            "        0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
            "        0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
            "        1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
            "        0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
            "        1, 0, 1, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhytESMXuVfm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BUILD MODEL"
      ],
      "metadata": {
        "id": "jHQdVxlE8wOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NVjh2PGFKOZW"
      },
      "outputs": [],
      "source": [
        "#build model\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self,x,hidden):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.long()\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        train_on_gpu=torch.cuda.is_available()\n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "        return hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAIN MODEL"
      ],
      "metadata": {
        "id": "gz5EfC3F9EYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define training device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdUOwhfmhT4E",
        "outputId": "0102a1b6-b09f-47bf-c37e-1362b18a3248"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs,model,optimizer,criterion,batch_size=batch_size,device=device):\n",
        "  clip=5 # gradient clipping\n",
        "  val_loss=float('inf')\n",
        "    # move model to GPU, if available\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    hidden_states = model.init_hidden(batch_size)\n",
        "    train_losses=0\n",
        "    valid_losses=0\n",
        "    val_acc=0\n",
        "    \n",
        "\n",
        "    for id,(reviews, labels) in enumerate(train_loader):\n",
        "\n",
        "      reviews, labels = reviews.to(device), labels.to(device)\n",
        "\n",
        "      hidden_states = tuple([each.data for each in hidden_states])\n",
        "\n",
        "      # clear grads \n",
        "      model.zero_grad()\n",
        "\n",
        "      # forwardpass\n",
        "      output, hidden_states = model(reviews, hidden_states)\n",
        "      \n",
        "      #loss\n",
        "      loss = criterion(output.squeeze(), labels.float())\n",
        "      train_losses+=loss.item()\n",
        "      #backpropagte\n",
        "      loss.backward()\n",
        "\n",
        "      #clip grad\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "      #update \n",
        "      optimizer.step()\n",
        "      \n",
        "      # free some memory\n",
        "      del reviews, labels\n",
        "\n",
        "\n",
        "    avg_train_loss= train_losses/len(train_loader)\n",
        "\n",
        "\n",
        "    #validation phase\n",
        "\n",
        "    model.eval()\n",
        "    hidden_states_v = model.init_hidden(batch_size)\n",
        "    \n",
        "    for id,(reviews, labels) in enumerate(valid_loader):\n",
        "\n",
        "        \n",
        "        hidden_states_v = tuple([each.data for each in hidden_states_v])\n",
        "        \n",
        "        reviews, labels = reviews.to(device), labels.to(device)\n",
        "        #forwardpass\n",
        "        output, hidden_states_v  = model(reviews, hidden_states_v )\n",
        "        #loss\n",
        "        loss_v = criterion(output.squeeze(), labels.float())\n",
        "        valid_losses += loss_v.item()\n",
        "\n",
        "        #calculate accuracy\n",
        "        predicted = torch.tensor([1 if i == True else 0 for i in output > 0.5], device=device)\n",
        "        equals = predicted == labels\n",
        "        acc = torch.mean(equals.type(torch.FloatTensor))\n",
        "        val_acc+=acc.item()\n",
        "        \n",
        "        # free some memory\n",
        "        del reviews, labels,predicted\n",
        "\n",
        "        #back to train mode\n",
        "        model.train()\n",
        "        \n",
        "    avg_valid_loss = valid_losses/len(valid_loader)\n",
        "    avg_valid_acc = val_acc/len(valid_loader)\n",
        "\n",
        "    if val_loss >= avg_valid_loss:\n",
        "      val_loss=avg_valid_loss\n",
        "     # Saving the model\n",
        "    save_path = './model.pth'\n",
        "    torch.save(model, save_path)\n",
        "     \n",
        "    print('model saved at valid loss: ',avg_valid_loss)\n",
        "    print('model saved at acc: ',avg_valid_acc)\n",
        "     \n",
        "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                \"Loss: {:.6f}...\".format(avg_train_loss),\n",
        "                \"Val Loss: {:.6f}\".format(avg_valid_loss),\n",
        "                \"Val accuracy: {:.6f}\".format(avg_valid_acc)) \n",
        "    print(\" \")\n",
        "    print(\"=\"*100)\n",
        "    print(\" \")\n",
        "\n"
      ],
      "metadata": {
        "id": "1EEJm-TpmnPj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,batch_size,criterion,device=device):\n",
        "  test_losses=0\n",
        "  test_acc=0\n",
        "  \n",
        "  model.eval()\n",
        "  for id,(reviews, labels) in enumerate(test_loader):\n",
        "\n",
        "        hidden_states_t = model.init_hidden(batch_size)\n",
        "        \n",
        "        hidden_states_t = tuple([each.data for each in  hidden_states_t])\n",
        "        \n",
        "        reviews, labels = reviews.to(device), labels.to(device)\n",
        "        #forwardpass\n",
        "        output,  hidden_states_t  = model(reviews, hidden_states_t )\n",
        "        #loss\n",
        "        loss_t = criterion(output.squeeze(), labels.float())\n",
        "        test_losses += loss_t.item()\n",
        "\n",
        "        #calculate accuracy\n",
        "        predicted = torch.tensor([1 if i == True else 0 for i in output > 0.5], device=device)\n",
        "        equals = predicted == labels\n",
        "        acc = torch.mean(equals.type(torch.FloatTensor))\n",
        "        test_acc+=acc.item()\n",
        "\n",
        "  avg_test_loss= test_losses/len(test_loader)\n",
        "  avg_test_acc= test_acc/len(test_loader)\n",
        "  print(\"test Loss: {:.6f}\".format(avg_test_loss),\n",
        "                \"test accuracy: {:.6f}\".format(avg_test_acc)) \n",
        "  print(\" \")\n",
        "  print(\"=\"*100)\n",
        "  print(\" \")\n"
      ],
      "metadata": {
        "id": "h5gkoNAa-JGg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(path):\n",
        "  model = torch.load(path)\n",
        "  return model"
      ],
      "metadata": {
        "id": "rkEC1dyGJK-f"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YtS7ksjrMuQ8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = vocab_size \n",
        "output_size = 1\n",
        "embedding_dim =512\n",
        "hidden_dim =128\n",
        "n_layers =2\n",
        "dropout=0.5\n",
        "model = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOk-iTAire8N",
        "outputId": "5dbaadab-b2c1-4b7e-e64b-1e280c205b22"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(35954, 512)\n",
            "  (lstm): LSTM(512, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss and optimization functions\n",
        "lr=0.0005\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "28MTG78UsceQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "epochs=10\n",
        "train(epochs,model,optimizer,criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bATH2j75vD-",
        "outputId": "5ffd1564-145c-42c9-f59c-9a55fab8cf3a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved at valid loss:  0.684916689991951\n",
            "model saved at acc:  0.546875\n",
            "Epoch: 1/10... Loss: 0.688903... Val Loss: 0.684917 Val accuracy: 0.546875\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.5329562276601791\n",
            "model saved at acc:  0.7421875\n",
            "Epoch: 2/10... Loss: 0.611685... Val Loss: 0.532956 Val accuracy: 0.742188\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.4520696997642517\n",
            "model saved at acc:  0.794921875\n",
            "Epoch: 3/10... Loss: 0.441884... Val Loss: 0.452070 Val accuracy: 0.794922\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.5101861283183098\n",
            "model saved at acc:  0.7890625\n",
            "Epoch: 4/10... Loss: 0.294503... Val Loss: 0.510186 Val accuracy: 0.789062\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.5084274560213089\n",
            "model saved at acc:  0.80859375\n",
            "Epoch: 5/10... Loss: 0.168606... Val Loss: 0.508427 Val accuracy: 0.808594\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.5982981100678444\n",
            "model saved at acc:  0.81640625\n",
            "Epoch: 6/10... Loss: 0.085102... Val Loss: 0.598298 Val accuracy: 0.816406\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.7111676782369614\n",
            "model saved at acc:  0.78515625\n",
            "Epoch: 7/10... Loss: 0.051611... Val Loss: 0.711168 Val accuracy: 0.785156\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.6920816749334335\n",
            "model saved at acc:  0.8125\n",
            "Epoch: 8/10... Loss: 0.039006... Val Loss: 0.692082 Val accuracy: 0.812500\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.7386784553527832\n",
            "model saved at acc:  0.8046875\n",
            "Epoch: 9/10... Loss: 0.026604... Val Loss: 0.738678 Val accuracy: 0.804688\n",
            " \n",
            "====================================================================================================\n",
            " \n",
            "model saved at valid loss:  0.8445011377334595\n",
            "model saved at acc:  0.798828125\n",
            "Epoch: 10/10... Loss: 0.015652... Val Loss: 0.844501 Val accuracy: 0.798828\n",
            " \n",
            "====================================================================================================\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inference\n",
        "test(model,32,criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4eGp9Z-g4PX",
        "outputId": "1c2a93bf-c661-4571-9bae-f82f53db2381"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test Loss: 0.852544 test accuracy: 0.790441\n",
            " \n",
            "====================================================================================================\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('/content/model.pth') \n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC95Aog1NH5b",
        "outputId": "f33abd26-f117-4a61-d386-b6ee6bf88d23"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(35954, 512)\n",
            "  (lstm): LSTM(512, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "S_qQI355KOhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2d9da7-01be-4c91-b6d0-5b0bc75ed462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a bad movie. NEGATIVE.\n",
            "I am very happy today. POSITIVE.\n",
            "I don't like this product it has a bad quality. NEGATIVE.\n"
          ]
        }
      ],
      "source": [
        "def process_text(text):\n",
        "  text=clean(text)\n",
        "  #remove stop words\n",
        "  text=remove_stopwords(text)\n",
        "  text=stemer(text)\n",
        "  text=' '.join(text)\n",
        "\n",
        "  #encode\n",
        "  encoded_text=encode_review(text,vocab=vocab)\n",
        "  padded_text= padding([encoded_text],100)\n",
        "  return padded_text\n",
        "\n",
        "def predict_text(text,model=model,device=device):\n",
        "    model.to(device)\n",
        "    text=process_text(text)\n",
        "    # convert to tensor to pass into your model\n",
        "    text_tensor = torch.from_numpy(text)\n",
        "    \n",
        "    batch_size = text_tensor.size(0)\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = model.init_hidden(batch_size)\n",
        "    \n",
        "    text_tensor = text_tensor.to(device)\n",
        "    \n",
        "    # get the output from the model\n",
        "    output, h = model(text_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "\n",
        "    if pred.item()==1:\n",
        "      return 'POSITIVE.'\n",
        "    else:\n",
        "      return 'NEGATIVE.'  \n",
        "  \n",
        "   \n",
        "\n",
        "   \n",
        "text=\"This is a bad movie.\"\n",
        "text2=\"I am very happy today.\"\n",
        "text3=\"I don't like this product it has a bad quality.\"\n",
        "print(text,predict_text(text))\n",
        "print(text2,predict_text(text2))\n",
        "print(text3,predict_text(text3))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}